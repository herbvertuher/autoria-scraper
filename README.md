<div align="center" style="margin-top: 0;">
  <h1>ğŸš— AutoRia Scraper âœ¨</h1>
</div>

---

This application is designed to scrape data periodically from the AutoRia platform, specifically focusing on used cars. The starting page URL can be hardcoded into the application.

## ğŸ‘€ Features
- The application is scheduled to run daily at a specified time (e.g., 12:00 PM) and traverse through all pages starting from the initial page, scraping data from each car listing.
- All scraped data is stored in a PostgreSQL database.
- Duplicate entries are filtered out to ensure data integrity.
- The application performs a daily database dump at a specified time (e.g., 11:00 PM) and saves dump files in the "dumps" folder located in the root directory of the application.
- Pip is used as the package manager.
- Application settings are stored in a `.env` file.

## ğŸ‘‰ Structure

    autoria-scraper/
    â”œâ”€â”€ utils
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ async_scraper.py
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ db_helper.py
    â”‚   â””â”€â”€ log.txt
    â”‚
    â”œâ”€â”€ dumps/
    â”‚
    â”œâ”€â”€ .env
    â”œâ”€â”€ main.py
    â”œâ”€â”€ README.py
    â””â”€â”€ requirements.txt

---

## ğŸš€ Setup

1ï¸âƒ£ **Clone the repository from GitHub:**
```shell
git clone https://github.com/herbvertuher/autoria-scraper
cd autoria-scraper
```

2ï¸âƒ£ **Install dependencies using pip:**
```shell
pip install -r requirements.txt
```

3ï¸âƒ£ **Set up PostgreSQL and create a database.**

4ï¸âƒ£ **Create a .env file** and specify the required settings (e.g., database connection details, starting page URL, scheduled times).

5ï¸âƒ£ **Run the application:**
 ```shell
python main.py
 ```

## âœŒï¸ Contributions
Contributions are welcome! Please fork the repository, make your changes, and submit a pull request.

## â˜ï¸ Disclaimer
This application is created for educational and demonstration purposes. Use responsibly and adhere to the terms of service of the AutoRia platform.
